{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6ddc3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# XGBoost Model for RedHat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484c46ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import xgboost as xgb\n",
    "import random\n",
    "from operator import itemgetter\n",
    "import time\n",
    "import copy\n",
    "\n",
    "random.seed(2016)\n",
    "\n",
    "#creating feature map\n",
    "def create_feature_map(features):\n",
    "    outfile = open('xgb.fmap', 'w')\n",
    "    for i, feat in enumerate(features):\n",
    "        outfile.write('{0}\\t{1}\\tq\\n'.format(i, feat))\n",
    "    outfile.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65eac34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_importance(gbm, features):\n",
    "    create_feature_map(features)\n",
    "    importance = gbm.get_fscore(fmap='xgb.fmap')\n",
    "    importance = sorted(importance.items(), key=itemgetter(1), reverse=True)\n",
    "    return importance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d4acd6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def intersect(a, b):\n",
    "    return list(set(a) & set(b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc84cc71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def run_single(train, test, features, target, random_state=0):\n",
    "    eta = 0.2\n",
    "    max_depth = 5\n",
    "    subsample = 0.8\n",
    "    colsample_bytree = 0.8\n",
    "    start_time = time.time()\n",
    "\n",
    "    print('XGBoost params. ETA: {}, MAX_DEPTH: {}, SUBSAMPLE: {}, COLSAMPLE_BY_TREE: {}'.format(eta, max_depth, subsample, colsample_bytree))\n",
    "    params = {\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"booster\" : \"gbtree\",\n",
    "        \"eval_metric\": \"auc\",\n",
    "        \"eta\": eta,\n",
    "        \"tree_method\": 'exact',\n",
    "        \"max_depth\": max_depth,\n",
    "        \"subsample\": subsample,\n",
    "        \"colsample_bytree\": colsample_bytree,\n",
    "        \"silent\": 1,\n",
    "        \"seed\": random_state,\n",
    "    }\n",
    "    num_boost_round = 115\n",
    "    early_stopping_rounds = 10\n",
    "    test_size = 0.1\n",
    "\n",
    "    X_train, X_valid = train_test_split(train, test_size=test_size, random_state=random_state)\n",
    "    print('Length train:', len(X_train.index))\n",
    "    print('Length valid:', len(X_valid.index))\n",
    "    y_train = X_train[target]\n",
    "    y_valid = X_valid[target]\n",
    "    dtrain = xgb.DMatrix(X_train[features], y_train)\n",
    "    dvalid = xgb.DMatrix(X_valid[features], y_valid)\n",
    "\n",
    "    watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "    gbm = xgb.train(params, dtrain, num_boost_round, evals=watchlist, early_stopping_rounds=early_stopping_rounds, verbose_eval=True)\n",
    "\n",
    "    print(\"Validating...\")\n",
    "    check = gbm.predict(xgb.DMatrix(X_valid[features]))\n",
    "    score = roc_auc_score(X_valid[target].values, check)\n",
    "    print('ROC auc score: {:.6f}'.format(score))\n",
    "\n",
    "    imp = get_importance(gbm, features)\n",
    "    print('Importance array: ', imp)\n",
    "\n",
    "    print(\"Predict test set...\")\n",
    "    test_prediction_probs = gbm.predict(xgb.DMatrix(test[features]))\n",
    "\n",
    "    print('Training time: {} minutes'.format(round((time.time() - start_time)/60, 2)))\n",
    "    return test_prediction_probs.tolist(), score\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca9e4e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Running Kfold\n",
    "def run_kfold(nfolds, train, test, features, target, random_state=0):\n",
    "    eta = 0.1\n",
    "    max_depth = 5\n",
    "    subsample = 0.8\n",
    "    colsample_bytree = 0.8\n",
    "    start_time = time.time()\n",
    "\n",
    "    print('XGBoost params. ETA: {}, MAX_DEPTH: {}, SUBSAMPLE: {}, COLSAMPLE_BY_TREE: {}'.format(eta, max_depth, subsample, colsample_bytree))\n",
    "    params = {\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"booster\" : \"gbtree\",\n",
    "        \"eval_metric\": \"auc\",\n",
    "        \"eta\": eta,\n",
    "        \"max_depth\": max_depth,\n",
    "        \"subsample\": subsample,\n",
    "        \"colsample_bytree\": colsample_bytree,\n",
    "        \"silent\": 1,\n",
    "        \"seed\": random_state\n",
    "    }\n",
    "    num_boost_round = 50\n",
    "    early_stopping_rounds = 10\n",
    "\n",
    "    yfull_train = dict()\n",
    "    yfull_test = copy.deepcopy(test[['activity_id']].astype(object))\n",
    "    kf = KFold(len(train.index), n_folds=nfolds, shuffle=True, random_state=random_state)\n",
    "    num_fold = 0\n",
    "    for train_index, test_index in kf:\n",
    "        num_fold += 1\n",
    "        print('Start fold {} from {}'.format(num_fold, nfolds))\n",
    "        X_train, X_valid = train[features].as_matrix()[train_index], train[features].as_matrix()[test_index]\n",
    "        y_train, y_valid = train[target].as_matrix()[train_index], train[target].as_matrix()[test_index]\n",
    "        X_test = test[features].as_matrix()\n",
    "\n",
    "        print('Length train:', len(X_train))\n",
    "        print('Length valid:', len(X_valid))\n",
    "\n",
    "        dtrain = xgb.DMatrix(X_train, y_train)\n",
    "        dvalid = xgb.DMatrix(X_valid, y_valid)\n",
    "\n",
    "        watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "        gbm = xgb.train(params, dtrain, num_boost_round, evals=watchlist, early_stopping_rounds=early_stopping_rounds, verbose_eval=True)\n",
    "        \n",
    "        print(\"Validating...\")\n",
    "        yhat = gbm.predict(xgb.DMatrix(X_valid[features]))\n",
    "        score = roc_auc_score(y_valid.tolist(), yhat)\n",
    "        print('Check error value: {:.6f}'.format(score))\n",
    "\n",
    "        # Each time store portion of precicted data in train predicted values\n",
    "        for i in range(len(test_index)):\n",
    "            yfull_train[test_index[i]] = yhat[i]\n",
    "\n",
    "        imp = get_importance(gbm, features)\n",
    "        print('Importance array: ', imp)\n",
    "\n",
    "        print(\"Predict test set...\")\n",
    "        test_prediction = gbm.predict(xgb.DMatrix(X_test), ntree_limit=gbm.best_iteration+1)\n",
    "        yfull_test['kfold_' + str(num_fold)] = test_prediction\n",
    "\n",
    "    # Copy dict to list\n",
    "    train_res = []\n",
    "    for i in sorted(yfull_train.keys()):\n",
    "        train_res.append(yfull_train[i])\n",
    "\n",
    "    score = roc_auc_score(train[target], np.array(train_res))\n",
    "    print('Check error value: {:.6f}'.format(score))\n",
    "\n",
    "    #mean for KFolds on test\n",
    "    merge = []\n",
    "    for i in range(1, nfolds+1):\n",
    "        merge.append('kfold_' + str(i))\n",
    "    yfull_test['mean'] = yfull_test[merge].mean(axis=1)\n",
    "\n",
    "    print('Training time: {} minutes'.format(round((time.time() - start_time)/60, 2)))\n",
    "    return yfull_test['mean'].values, score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889d043f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Creating output table\n",
    "def output_table(score, test, prediction):\n",
    "    now = datetime.datetime.now()\n",
    "    sub_file = 'output_table_' + str(score) + '_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "    print('Writing Output Table: ', sub_file)\n",
    "    f = open(sub_file, 'w')\n",
    "    f.write('activity_id,outcome\\n')\n",
    "    total = 0\n",
    "    for id in test['activity_id']:\n",
    "        str1 = str(id) + ',' + str(prediction[total])\n",
    "        str1 += '\\n'\n",
    "        total += 1\n",
    "        f.write(str1)\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd029d35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_features(train, test):\n",
    "    trainval = list(train.columns.values)\n",
    "    testval = list(test.columns.values)\n",
    "    output = intersect(trainval, testval)\n",
    "    output.remove('people_id')\n",
    "    output.remove('activity_id')\n",
    "    return sorted(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eafc33b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Reading datasets\n",
    "def read_train_test():\n",
    "\n",
    "    print(\"Reading people.csv...\")\n",
    "    people = pd.read_csv(\"D:/MSBA/Machine Learning/Report 1/people.csv/people.csv\",\n",
    "                       dtype={'people_id': str,\n",
    "                              'activity_id': str,\n",
    "                              'char_38': np.int32},\n",
    "                       parse_dates=['date'])\n",
    "\n",
    "    print(\"Loading train.csv...\")\n",
    "    train = pd.read_csv(\"D:/MSBA/Machine Learning/Report 1/act_train.csv/act_train.csv\",\n",
    "                        dtype={'people_id': str,\n",
    "                               'activity_id': str,\n",
    "                               'outcome': np.int8},\n",
    "                        parse_dates=['date'])\n",
    "\n",
    "    print(\"Loading test.csv...\")\n",
    "    test = pd.read_csv(\"D:/MSBA/Machine Learning/Report 1/act_test.csv/act_test.csv\",\n",
    "                       dtype={'people_id': str,\n",
    "                              'activity_id': str},\n",
    "                       parse_dates=['date'])\n",
    "\n",
    "    print(\"Processing tables...\")\n",
    "    for table in [train, test]:\n",
    "        table['year'] = table['date'].dt.year\n",
    "        table['month'] = table['date'].dt.month\n",
    "        table['day'] = table['date'].dt.day\n",
    "        table.drop('date', axis=1, inplace=True)\n",
    "        table['activity_category'] = table['activity_category'].str.lstrip('type ').astype(np.int32)\n",
    "        for i in range(1, 11):\n",
    "            table['char_' + str(i)].fillna('type -999', inplace=True)\n",
    "            table['char_' + str(i)] = table['char_' + str(i)].str.lstrip('type ').astype(np.int32)\n",
    "\n",
    "    people['year'] = people['date'].dt.year\n",
    "    people['month'] = people['date'].dt.month\n",
    "    people['day'] = people['date'].dt.day\n",
    "    people.drop('date', axis=1, inplace=True)\n",
    "    people['group_1'] = people['group_1'].str.lstrip('group ').astype(np.int32)\n",
    "    for i in range(1, 10):\n",
    "        people['char_' + str(i)] = people['char_' + str(i)].str.lstrip('type ').astype(np.int32)\n",
    "    for i in range(10, 38):\n",
    "        people['char_' + str(i)] = people['char_' + str(i)].astype(np.int32)\n",
    "\n",
    "    print(\"Merging...\")\n",
    "    train = pd.merge(train, people, how='left', on='people_id')\n",
    "    test = pd.merge(test, people, how='left', on='people_id')\n",
    "    train.fillna(-999, inplace=True)\n",
    "    test.fillna(-999, inplace=True)\n",
    "\n",
    "    features = get_features(train, test)\n",
    "    return train, test, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1a9e6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Calling all the function\n",
    "train, test, features = read_train_test()\n",
    "print('Length of train: ', len(train))\n",
    "print('Length of test: ', len(test))\n",
    "print('Features [{}]: {}'.format(len(features), sorted(features)))\n",
    "\n",
    "test_prediction, score = run_single(train, test, features, 'outcome')\n",
    "\n",
    "output_table(score, test, test_prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcfc409",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c6e1f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a23902d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609ccba6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Logistic Regression for RedHat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f908894f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "#Leave One Out as a function\n",
    "def LeaveOneOut(data1, data2, columnName, useLOO=False):\n",
    "    grpOutcomes = data1.groupby(columnName).mean().reset_index()\n",
    "    outcomes = data2['outcome'].values\n",
    "    x = pd.merge(\n",
    "    data2[[columnName, 'outcome']],\n",
    "    grpOutcomes,\n",
    "    suffixes=('x_', ''),\n",
    "    how='left',\n",
    "    on=columnName)['outcome']\n",
    "\n",
    "    if(useLOO):\n",
    "        x = ((x*x.shape[0])-outcomes)/(x.shape[0]-1)\n",
    "    return x.fillna(x.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d612be0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Main Function\n",
    "def main():\n",
    "    directory = 'D:/MSBA/Machine Learning/Report 1/'\n",
    "    train_L = pd.read_csv(directory+'act_train.csv/act_train.csv',\n",
    "                        usecols=['people_id', 'outcome'])\n",
    "    \n",
    "    test_L = pd.read_csv(directory+'act_test.csv/act_test.csv',\n",
    "                       usecols=['activity_id', 'people_id'])\n",
    "    \n",
    "    people_L = pd.read_csv(directory+'/people.csv/people.csv',\n",
    "                         usecols=['people_id',\n",
    "                                  'group_1',\n",
    "                                  'char_2',\n",
    "                                  'char_38'])\n",
    "    \n",
    "    train_L = pd.merge(train_L, people_L, how='left', on='people_id')\n",
    "\n",
    "    train_L.fillna('-999', inplace=True)\n",
    "    lootrain = pd.DataFrame()\n",
    "    for col in train_L.columns:\n",
    "        if(col != 'outcome' and col != 'people_id'):\n",
    "            print(col)\n",
    "            lootrain[col] = LeaveOneOut(train_L, train_L, col, True).values\n",
    "    lr = LogisticRegression(C=100000.0)\n",
    "    lr.fit(lootrain[['group_1', 'char_2', 'char_38']], train_L['outcome'])\n",
    "    preds = lr.predict_proba(lootrain[['group_1', 'char_2', 'char_38']])[:, 1]\n",
    "    print('roc', roc_auc_score(train_L.outcome, preds))\n",
    "    \n",
    "    test_L = pd.read_csv(directory+'act_test.csv/act_test.csv',\n",
    "                       usecols=['activity_id', 'people_id'])\n",
    "    \n",
    "    test_L = pd.merge(test_L, people_L, how='left', on='people_id')\n",
    "    \n",
    "    test_L.fillna('-999', inplace=True)\n",
    "    activity_id = test_L.activity_id.values\n",
    "    test_L.drop('activity_id', inplace=True, axis=1)\n",
    "    test_L['outcome'] = 0\n",
    "    lootest = pd.DataFrame()\n",
    "    for col in train_L.columns:\n",
    "        if(col != 'outcome' and col != 'people_id'):\n",
    "            print(col)\n",
    "            lootest[col] = LeaveOneOut(train_L, test_L, col, False).values\n",
    "    preds = lr.predict_proba(lootest[['group_1', 'char_2', 'char_38']])[:, 1]\n",
    "    Logistic_Table = pd.DataFrame()\n",
    "    Logistic_Table['activity_id'] = activity_id\n",
    "    Logistic_Table['outcome'] = preds\n",
    "    Logistic_Table.to_csv('Logistic_Output_Table.csv', index=False, float_format='%.3f')\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print('Starting')\n",
    "    main()\n",
    "    print('Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf417cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad82bc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea80840f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3998729",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b77ca4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import linear_model\n",
    "from sklearn import model_selection\n",
    "\n",
    "print(\"Loading Train data...\")\n",
    "train = pd.read_csv('D:/MSBA/Machine Learning/Report 1/act_train.csv/act_train.csv', dtype={'people_id': str, 'activity_id': str, 'outcome': np.int8}, parse_dates=['date'])\n",
    "\n",
    "\n",
    "Y = train['outcome']\n",
    "\n",
    "train.drop('activity_id',axis=1,inplace=True)\n",
    "train.drop('date',axis=1,inplace=True)\n",
    "train.drop('outcome',axis=1,inplace=True)\n",
    "\n",
    "print(\"Loading Test data...\")\n",
    "test = pd.read_csv('D:/MSBA/Machine Learning/Report 1/act_test.csv/act_test.csv', dtype={'people_id': str, 'activity_id': str}, parse_dates=['date'])\n",
    "\n",
    "act_id = test['activity_id']\n",
    "\n",
    "test.drop('activity_id',axis=1,inplace=True)\n",
    "test.drop('date',axis=1,inplace=True)\n",
    "\n",
    "print(\"Loading people data...\")\n",
    "people = pd.read_csv('D:/MSBA/Machine Learning/Report 1/people.csv/people.csv', dtype={'people_id': str, 'activity_id': str, 'char_38': np.int32}, parse_dates=['date'])\n",
    "\n",
    "train['activity_category'] = train['activity_category'].str.lstrip('type ').astype(np.int32)\n",
    "test['activity_category'] = test['activity_category'].str.lstrip('type ').astype(np.int32)\n",
    "\n",
    "for i in range(1,11):\n",
    "    charMax = train['char_'+str(i)].value_counts().idxmax()\n",
    "    train['char_'+str(i)].fillna(charMax, inplace=True)\n",
    "    train['char_'+str(i)] = train['char_'+str(i)].str.lstrip('type ').astype(np.int32)\n",
    "    test['char_'+str(i)].fillna(charMax, inplace=True)\n",
    "    test['char_'+str(i)] = test['char_'+str(i)].str.lstrip('type ').astype(np.int32)\n",
    "\n",
    "people['group_1'] = people['group_1'].str.lstrip('group ').astype(np.int32)\n",
    "people.drop('date',axis=1,inplace=True)\n",
    "\n",
    "for i in range(1, 10):\n",
    "    people['char_' + str(i)] = people['char_' + str(i)].str.lstrip('type ').astype(np.int32)\n",
    "for i in range(10, 38):\n",
    "    people['char_' + str(i)] = people['char_' + str(i)].astype(np.int32)\n",
    "\n",
    "print(\"Merging data...\")\n",
    "train = pd.merge(train, people, how='left', on='people_id')\n",
    "test = pd.merge(test, people, how='left', on='people_id')\n",
    "\n",
    "del people\n",
    "\n",
    "train.drop('people_id',axis=1,inplace=True)\n",
    "test.drop('people_id',axis=1,inplace=True)\n",
    "\n",
    "X = train.values\n",
    "testX = test.values\n",
    "\n",
    "print(\"Running Random Forest\")\n",
    "dt_regressor = DecisionTreeRegressor()\n",
    "rf_regressor200 = RandomForestClassifier(n_estimators = 200)\n",
    "log_regressor = linear_model.LogisticRegression()\n",
    "mlp_regressor = MLPClassifier(activation='logistic')\n",
    "\n",
    "\n",
    "rf_regressor200.fit(X,Y)\n",
    "predict = rf_regressor200.predict(testX)\n",
    "\n",
    "wrt = True\n",
    "if wrt:\n",
    "    output_rfc = open('Output_rfc.csv','w')\n",
    "    output_rfc.write('activity_id,outcome\\n')\n",
    "    for i in range(0,len(predict)):\n",
    "        output_rfc.write(str(act_id[i])+\",\"+str(predict[i])+\"\\n\")\n",
    "    output_rfc.flush()\n",
    "    print(\"Finished...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7eddfc1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#ROC Curve Graph\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# predict probabilities for the test set\n",
    "predict_probs = rf_regressor200.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(Y_test, predict_probs)\n",
    "\n",
    "# Compute ROC AUC score\n",
    "roc_auc = roc_auc_score(Y_test, predict_probs)\n",
    "print(f\"ROC AUC Score: {roc_auc}\")\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label='ROC curve (AUC = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='red', lw=2, linestyle='--', label='Random Guess')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3935df6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
